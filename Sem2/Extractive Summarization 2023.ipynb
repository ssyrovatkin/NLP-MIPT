{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":11329,"status":"ok","timestamp":1681129796533,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"OqkLTkFRfXvA"},"outputs":[],"source":["!wget -q https://www.dropbox.com/s/43l702z5a5i2w8j/gazeta_train.txt\n","!wget -q https://www.dropbox.com/s/k2egt3sug0hb185/gazeta_val.txt\n","!wget -q https://www.dropbox.com/s/3gki5n5djs9w0v6/gazeta_test.txt"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7806,"status":"ok","timestamp":1681137288226,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"SXS1sdYZCluU","outputId":"056e4b70-554f-482f-804c-f2c2f62f4ca6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.9/dist-packages (0.13.3)\n","Requirement already satisfied: razdel in /usr/local/lib/python3.9/dist-packages (0.5.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (3.1)\n","Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.9/dist-packages (0.9.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n","Requirement already satisfied: rouge==0.3.1 in /usr/local/lib/python3.9/dist-packages (0.3.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.10.7)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.0)\n","Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.9/dist-packages (from pymorphy2) (0.6.2)\n","Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from pymorphy2) (0.7.2)\n","Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.9/dist-packages (from pymorphy2) (2.4.417127.4579844)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install --upgrade tokenizers razdel torch networkx pymorphy2 nltk rouge==0.3.1"]},{"cell_type":"markdown","metadata":{"id":"eesnclfDDV3F"},"source":["Посмотрим на то, как устроен датасет"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":606,"status":"ok","timestamp":1681138190996,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"5pZ2UGS2DGjH"},"outputs":[],"source":["import json\n","import random\n","from tqdm import tqdm\n","\n","def read_gazeta_records(file_name):\n","    records = []\n","    with open(file_name, \"r\") as r:\n","        for line in r:\n","            records.append(json.loads(line))\n","\n","    random.shuffle(records)\n","\n","    return records"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2569,"status":"ok","timestamp":1681138194588,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"GNDp-BunEA91"},"outputs":[],"source":["train_records = read_gazeta_records(\"gazeta_train.txt\")\n","val_records = read_gazeta_records(\"gazeta_val.txt\")\n","test_records = read_gazeta_records(\"gazeta_test.txt\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1681138194588,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"r4F9ga5zvL0T","outputId":"c4bca7d4-edfe-421e-8d03-cb911ab2d43b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'url': 'https://www.gazeta.ru/tech/2019/03/25_a_12263077.shtml',\n"," 'text': 'На входе в новый магазин Tele2 посетитель замечает, что привычную надпись «салон связи» заменяет вывеска «Другие правила», а описание режима работы – призыв «Общайтесь». Компания заявляет, что каждый элемент новой розницы прошел через фильтр диджитализации и концепцию «других правил». Цифровой подход воплотился в сервисе, ассортименте и коммуникациях. Аудитория оператора становится все более цифровой, поэтому запуск формата – логичный ответ на тренд диждитализации. «По итогам прошлого года потребление интернет-трафика на одного пользователя Tele2 выросло почти в полтора раза. Клиенты приобрели в два раза больше смартфонов, чем годом ранее. Аудитория нашего мобильного приложения также удвоилась. Вывод очевиден – наши клиенты уходят в цифру», – заключил Игорь Майстренко , директор по продажам и развитию массового сегмента Tele2. Витрины нового магазина оформлены в непривычном для салона связи дизайне. Оператор ориентировался не на отраслевые стандарты, а стиль fashion-бутиков и модных универмагов. «Каждый медиафасад становится не просто цифровым арт-объектом, но способом коммуникации с клиентом. Контент подается при помощи 3D-инсталляции. Комбинация виртуальных кубов и цифрового дисплея позволяет информировать жителей города об услугах Tele2», – сообщили в пресс-службе компании. При разработке нового формата компания провела исследования и получила интересные результаты. Выяснилось, что клиенты хотят приходить в салон не для решения проблем, а взаимодействия с новыми гаджетами. Так тема digital стала главной идеей новой концепции. В салонах нового формата digital-инструменты упрощают жизнь как клиенту, так и продавцу. Например, используя планшет, консультант может обслужить посетителя в любой точке зала. Это и база данных, и точка продаж — стоять в очереди необязательно. В магазине нет традиционных кассовых зон, что, как считают в компании, снимает барьеры в общении. «Digital-сервис позволяет наладить открытое взаимодействие с клиентами. Эти изменения представляют глубинную трансформацию и эволюцию в коммуникации консультанта и посетителя», — считает Майстренко. В магазине установлены виртуальные витрины, которая частично выполняют функцию терминала самообслуживания: здесь клиенты могут сменить тариф, выбрать номер, оставить заявку для перехода в сеть Tele2. Цифровой подход применили к выкладке устройств в салоне Tele2. Ее в компании называют «интерактивной витриной». Выбор определения объясняется так: как только клиент берет в руки смартфон, на экране автоматически появляются технические характеристики гаджета и оценки пользователей из интернета. Похоже, бумажки с мелкими буквами уходят в прошлое, как и мучительное сравнение двух смартфонов по характеристикам с ценников. Удобство в выборе традиционно связано с выкладкой товара — в таком салоне она тоже должна быть «умной». Устройства не просто лежат стройными рядами, а организованы в экосистемы, то есть дополняют друг друга. Например, клиенты могут протестировать смартфон, а затем докупить к нему наушники, часы или другие гаджеты. «Умная розница» салона связи не могла обойтись без продажи «умных» вещей. Это роботы, дроны, GoPro- и другие action-камеры. Установленные здесь цифровые экраны покажут, как эти гаджеты можно использовать на практике. В зоне располагаются и решения для «умного дома». В Tele2 объясняют, что его компоненты выглядят вполне обычно, а вот чтобы заинтересовать клиента, надо показать устройство в действии. Макет демонстрирует, какие сценарии можно реализовать при помощи смартфона и компонентов умного дома: защитить от протечек, дистанционно включить кофемашину или повысить температуру в доме. В новом салоне появился и кофе-корнер. Оператор предлагает чашку бесплатного кофе, которую можно получить через мобильное приложение. Возможность присесть и отдохнуть в салоне связи — новое слово. Тему неоператорских предложений продолжают установленные в салоне постаматы, в которых можно забрать интернет-заказы. Стоимость нового салона компания не раскрывает. Как объясняют в Tele2, оценивать по нему затраты на одну точку было бы неверно. Стоимость салона на Тверской включает разработку концепции и инновации, которые применяются в отрасли впервые. Многие из них являются прообразом будущих решений и при тиражировании будут удешевляться. Так, говорят в компании, в конечном итоге расходы снизятся до 25% от стоимости магазина-прототипа в центре Москвы. Новый салон – экспериментальный, но уже к следующем году digital-формат станет основным для розницы компании. В апреле этого года новые магазины откроются в Ярославле, где оператор скоро запускает сеть, и Санкт-Петербурге.',\n"," 'title': 'Tele2 открыла первый в России digital-салон ',\n"," 'summary': 'Оператор мобильной связи Tele2 запускает новый цифровой формат розницы: первый digital-магазин открылся в Москве на Тверской улице. Оформление фасада по принципу модных бутиков, зона «умного дома», интерактивные и виртуальные витрины, продавцы с планшетами и заказ бесплатного кофе через приложение – так компания отвечает на запрос «цифровой» аудитории. К следующему году концепция станет основной для всей розничной сети Tele2.',\n"," 'date': '2019-03-25 08:00:08'}"]},"metadata":{},"execution_count":3}],"source":["train_records[20]"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1681138194589,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"oIfbsLj2gtBb","outputId":"1c857d43-1ab9-432b-8b38-eb971d7c71ee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["52400"]},"metadata":{},"execution_count":4}],"source":["len(train_records)"]},{"cell_type":"markdown","metadata":{"id":"_1sl7s2qB-N_"},"source":["## Lead-3"]},{"cell_type":"markdown","metadata":{"id":"gBNeldXoDevM"},"source":["Бейзлайн - первые 3 предложения текста в качестве summary.\n"]},{"cell_type":"markdown","metadata":{"id":"J-gEkSkQDk0P"},"source":["В качестве метрик здесь и далее используем BLEU и ROUGE."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1711,"status":"ok","timestamp":1681138198205,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"8fVfdfCyCALH"},"outputs":[],"source":["from nltk.translate.bleu_score import corpus_bleu\n","from rouge import Rouge\n","\n","def calc_scores(references, predictions, metric=\"all\"):\n","    print(\"Tar:\", references[0])\n","    print(\"Pred:\", predictions[0])\n","\n","    if metric in (\"bleu\", \"all\"):\n","        print(\"BLEU: \", corpus_bleu([[r.split()] for r in references], [p.split() for p in predictions]))\n","    if metric in (\"rouge\", \"all\"):\n","        rouge = Rouge()\n","        scores = rouge.get_scores(predictions, references, avg=True)\n","        print(\"ROUGE: \", scores)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8722,"status":"ok","timestamp":1681138206923,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"zAo9zv_rPtb6","outputId":"15de49b7-0abf-49c9-ccb7-e3057a22861b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tar: хорею гентингтона, тяжелое наследственное заболевание нервной системы, можно вылечить, считает международная группа исследователей. им удалось снизить число тринуклеотидных повторов, которое приводит к появлению симптомов. также новый способ лечения будет эффективен и против других заболеваний похожей природы.\n","Pred: международная команда исследователей под руководством специалистов из канадской детской больницы sickkids нашла способ вылечить хорею гентингтона или, как минимум, замедлить ее развитие, а также облегчить симптомы других заболеваний сходной природы. работа была опубликована в журнале nature genetics. хорея гентингтона — генетическое заболевание нервной системы, которое возникает из-за мутации гена htt.\n","BLEU:  0.07892949436329745\n","ROUGE:  {'rouge-1': {'f': 0.26346609918664804, 'p': 0.24937931490857518, 'r': 0.29722136891010914}, 'rouge-2': {'f': 0.11164812927783638, 'p': 0.10454227138078512, 'r': 0.12930484255529515}, 'rouge-l': {'f': 0.22648967863851122, 'p': 0.226885814423179, 'r': 0.27022840141755444}}\n"]}],"source":["import razdel\n","\n","def calc_lead_n_score(records, n=1, lower=True, nrecords=1000):\n","    references = []\n","    predictions = []\n","\n","    for record in records[:nrecords]:\n","        summary = record[\"summary\"]\n","        summary = summary if not lower else summary.lower()\n","        references.append(summary)\n","\n","        text = record[\"text\"]\n","        sentences = [sentence.text.lower() for sentence in razdel.sentenize(text)]\n","        prediction = \" \".join(sentences[:n])\n","        predictions.append(prediction)\n","\n","    calc_scores(references, predictions)\n","\n","calc_lead_n_score(test_records, n=3)"]},{"cell_type":"markdown","metadata":{"id":"QsAcVSli3r3S"},"source":["##TextRank"]},{"cell_type":"markdown","metadata":{"id":"c7jAQp-_Ds98"},"source":["TextRank - unsupervised метод для составления кратких выжимок из текста. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":197859,"status":"ok","timestamp":1680799676119,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"m2GwyRrMPAzS","outputId":"96d62508-bf99-4730-a1fb-3f71150209d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tar: в воронежской области врач-рентгенолог оказалась не в состоянии помочь ребенку, поскольку была сильно пьяна. на видеозаписи, сделанной в медучреждении, видно, что женщина не может подняться с кровати и не реагирует на возмущенные крики пациентов в свой адрес. позднее она пояснила, что употребила алкоголь из-за сложных семейных обстоятельств.\n","Pred: как рассказал отец ребенка в соцсетях, он привел сына на рентген, поскольку опасался, что у того сломана рука. в ее объяснительной сказано, что у нее сложились вот такие семейные обстоятельства», – подчеркнул представитель црб. житель приморья также выложил в соцсети видео и заявил, что если бы врач находился на работе в трезвом состоянии, возможно, он смог бы оказать пострадавшему квалифицированную помощь. некоторые пользователи узнали медика и сообщили в комментариях, что у него давно наблюдаются проблемы с алкоголем.\n","BLEU:  0.021070976947306745\n","ROUGE:  {'rouge-1': {'f': 0.15962779073032757, 'p': 0.13369862066804186, 'r': 0.21490563304814847}, 'rouge-2': {'f': 0.03461282961168434, 'p': 0.028183103836621395, 'r': 0.04922776813554147}, 'rouge-l': {'f': 0.1267404165264273, 'p': 0.11877102196276716, 'r': 0.19104667175693033}}\n","Tar: в воронежской области врач-рентгенолог оказалась не в состоянии помочь ребенку, поскольку была сильно пьяна. на видеозаписи, сделанной в медучреждении, видно, что женщина не может подняться с кровати и не реагирует на возмущенные крики пациентов в свой адрес. позднее она пояснила, что употребила алкоголь из-за сложных семейных обстоятельств.\n","Pred: как рассказал отец ребенка в соцсетях, он привел сына на рентген, поскольку опасался, что у того сломана рука. в ее объяснительной сказано, что у нее сложились вот такие семейные обстоятельства», – подчеркнул представитель црб. житель приморья также выложил в соцсети видео и заявил, что если бы врач находился на работе в трезвом состоянии, возможно, он смог бы оказать пострадавшему квалифицированную помощь. некоторые пользователи узнали медика и сообщили в комментариях, что у него давно наблюдаются проблемы с алкоголем.\n","BLEU:  0.024925922456222653\n","ROUGE:  {'rouge-1': {'f': 0.1706488590587267, 'p': 0.1399432381486689, 'r': 0.23750775830621115}, 'rouge-2': {'f': 0.04251062667671106, 'p': 0.03406954342385603, 'r': 0.06206319129289799}, 'rouge-l': {'f': 0.13331673948803202, 'p': 0.12402804150917934, 'r': 0.21082610274472954}}\n"]}],"source":["from itertools import combinations\n","import networkx as nx\n","import pymorphy2\n","import numpy as np\n","\n","def unique_words_similarity(words1, words2):\n","    '''\n","    Функция подсчёта близости предложений на основе пересечения слов\n","    ''' \n","    words1 = set(words1)\n","    words2 = set(words2)\n","  \n","    if not len(words1) or not len(words2):\n","        return 0.0\n","\n","    return len(words1 & words2) / np.log10(len(words1) * len(words2))\n","\n","def gen_text_rank_summary(text, calc_similarity=unique_words_similarity, summary_part=0.1, lower=True, morph=None):\n","    '''\n","    Составление summary с помощью TextRank\n","    '''\n","    # Разбиваем текст на предложения\n","    sentences = [sentence.text for sentence in razdel.sentenize(text)]\n","    n_sentences = len(sentences)\n","\n","    # Токенизируем предложения\n","    sentences_words = [[token.text.lower() if lower else token.text for token in razdel.tokenize(sentence)] for sentence in sentences]\n","\n","    # При необходимости лемматизируем слова\n","    if morph is not None:\n","        sentences_words = [[morph.parse(word)[0].normal_form for word in words] for words in sentences_words]\n","\n","    # Для каждой пары предложений считаем близость\n","    pairs = combinations(range(n_sentences), 2)\n","    scores = [(i, j, calc_similarity(sentences_words[i], sentences_words[j])) for i, j in pairs]\n","\n","    # Строим граф с рёбрами, равными близости между предложениями\n","    g = nx.Graph()\n","    g.add_weighted_edges_from(scores)\n","\n","    # Считаем PageRank\n","    pr = nx.pagerank(g)\n","    result = [(i, pr[i], s) for i, s in enumerate(sentences) if i in pr]\n","    result.sort(key=lambda x: x[1], reverse=True)\n","\n","    # Выбираем топ предложений\n","    n_summary_sentences = max(int(n_sentences * summary_part), 1)\n","    result = result[:n_summary_sentences]\n","\n","    # Восстанавливаем оригинальный их порядок\n","    result.sort(key=lambda x: x[0])\n","\n","    # Восстанавливаем текст выжимки\n","    predicted_summary = \" \".join([sentence for i, proba, sentence in result])\n","    predicted_summary = predicted_summary.lower() if lower else predicted_summary\n","    return predicted_summary\n","\n","def calc_text_rank_score(records, calc_similarity=unique_words_similarity, summary_part=0.1, lower=True, nrows=1000, morph=None):\n","    references = []\n","    predictions = []\n","\n","    for record in records[:nrows]:\n","        summary = record[\"summary\"]\n","        summary = summary if not lower else summary.lower()\n","        references.append(summary)\n","\n","        text = record[\"text\"]\n","        predicted_summary = gen_text_rank_summary(text, calc_similarity, summary_part, lower, morph=morph)\n","        text = text if not lower else text.lower()\n","        predictions.append(predicted_summary)\n","\n","    calc_scores(references, predictions)\n","\n","morph = pymorphy2.MorphAnalyzer()\n","calc_text_rank_score(test_records)\n","calc_text_rank_score(test_records, morph=morph)"]},{"cell_type":"markdown","metadata":{"id":"Ac8UYVqJOLg6"},"source":["### **Задание 1**\n","\n","Сделайте TextRank с другой мерой близости предложений: по FastText, ELMo или BERT эмбеддингам"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"fNouht2I21yk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681130088845,"user_tz":-180,"elapsed":44211,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"}},"outputId":"44cb3bc2-6474-4a4a-aadb-f4072654aaaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Archive:  /content/gdrive/My Drive/Colab Notebooks/213.zip\n","  inflating: meta.json               \n","  inflating: model.model             \n","  inflating: model.model.vectors_ngrams.npy  \n","  inflating: model.model.vectors.npy  \n","  inflating: model.model.vectors_vocab.npy  \n","  inflating: README                  \n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!unzip '/content/gdrive/My Drive/Colab Notebooks/213.zip'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QyPzG6uP3G7G"},"outputs":[],"source":["import gensim\n","import numpy as np\n","\n","model_path = 'model.model'\n","\n","model = gensim.models.fasttext.FastTextKeyedVectors.load(model_path)\n","model.adjust_vectors()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Wb4ZZWs15jf"},"outputs":[],"source":["from scipy import spatial\n","from numpy import dot\n","from numpy.linalg import norm\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","def fast_text_sentences_similarity(words1, words2):\n","    '''\n","    Функция подсчёта близости предложений на основе пересечения слов\n","    ''' \n","    words1 = set(words1)\n","    words2 = set(words2)\n","    embeddings1 = np.array([model.get_vector(word.lower()) if word.lower() in model.key_to_index else np.zeros((model.vector_size,))\n","                        for word in words1])\n","    \n","    embeddings2 = np.array([model.get_vector(word.lower()) if word.lower() in model.key_to_index else np.zeros((model.vector_size,))\n","                    for word in words2])\n","    \n","    sent1 = np.mean(embeddings1, axis=0)\n","    sent2 = np.mean(embeddings2, axis=0)\n","\n","    return 1 - spatial.distance.cosine(sent1, sent2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":578544,"status":"ok","timestamp":1680793028611,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"9MhUkHTH34jJ","outputId":"900496eb-bd5e-435a-f8c3-a59ebd654282"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/scipy/spatial/distance.py:622: RuntimeWarning: invalid value encountered in double_scalars\n","  dist = 1.0 - uv / np.sqrt(uu * vv)\n"]},{"name":"stdout","output_type":"stream","text":["Tar: светлана лобода отпраздновала свой 37-й день рождения в компании лидера немецкой рок-группы rammstein тилля линдеманна. певица поделилась с подписчиками фотографией с камерного застолья в свою честь, на котором помимо предполагаемого возлюбленного присутствовали друзья и команда знаменитости.\n","Pred: в самом начале беседы собчак заверила лободу, что не станет расспрашивать ее о знаменитом рокере, поскольку ей известно, что та подобные вопросы не любит и не отвечает на них. следом же журналистка напомнила об интервью певицы в шоу рэпера басты, когда та обмолвилась о том, что не может публично говорить о своей личной жизни из-за наличия некоего контракта. дальнейшие попытки обсудить волнующую всю страну тему лобода, не без труда маскируя раздражение, отклонила смягчающей фразой о том, что собчак ей очень симпатична, но она «ничего не получит в ответ».\n","BLEU:  0.016490425580728312\n","ROUGE:  {'rouge-1': {'f': 0.14890736534842813, 'p': 0.12012349893901877, 'r': 0.20965926075082728}, 'rouge-2': {'f': 0.02831294493651511, 'p': 0.022411214493318635, 'r': 0.04138018190932649}, 'rouge-l': {'f': 0.1159609916751527, 'p': 0.10658211699233812, 'r': 0.18604998180003893}}\n","Tar: светлана лобода отпраздновала свой 37-й день рождения в компании лидера немецкой рок-группы rammstein тилля линдеманна. певица поделилась с подписчиками фотографией с камерного застолья в свою честь, на котором помимо предполагаемого возлюбленного присутствовали друзья и команда знаменитости.\n","Pred: в самом начале беседы собчак заверила лободу, что не станет расспрашивать ее о знаменитом рокере, поскольку ей известно, что та подобные вопросы не любит и не отвечает на них. ксения, в свою очередь, усомнилась в том, что подобное желание может продлиться долго у женщин подобных им (телеведущая говорила о себе и лободе). певица подкрепила свое видение, приведя в пример историю любви владимира высоцкого и марины влади (их роман продлился 12 лет, и все эти годы они жили на две страны — «газета.ru»).\n","BLEU:  0.017969770376572863\n","ROUGE:  {'rouge-1': {'f': 0.15483200112606466, 'p': 0.12438420437492323, 'r': 0.21935438572598742}, 'rouge-2': {'f': 0.03205566032006046, 'p': 0.02540980149994756, 'r': 0.04670946860601438}, 'rouge-l': {'f': 0.12002729458527898, 'p': 0.11022602031118013, 'r': 0.19437393187668522}}\n"]}],"source":["morph = pymorphy2.MorphAnalyzer()\n","calc_text_rank_score(test_records, calc_similarity=fast_text_sentences_similarity)\n","calc_text_rank_score(test_records, calc_similarity=fast_text_sentences_similarity, morph=morph)"]},{"cell_type":"markdown","metadata":{"id":"xdTrfxycB7cd"},"source":["## Oracle summary"]},{"cell_type":"markdown","metadata":{"id":"6Q7DeHDYFSjX"},"source":["Для сведения задачи к extractive summarization мы должны выбрать те предложения из оригинального текста, которые наиболее похожи на наше целевое summary по нашим метрикам."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1681138206924,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"Sxsc0Orf8hGq"},"outputs":[],"source":["import copy\n","\n","def build_oracle_summary_greedy(text, gold_summary, calc_score, lower=True, max_sentences=30, max_summary_sentences=5):\n","    '''\n","    Жадное построение oracle summary\n","    '''\n","    gold_summary = gold_summary.lower() if lower else gold_summary\n","    # Делим текст на предложения\n","    sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n","    n_sentences = len(sentences)\n","    oracle_summary_sentences = set()\n","    score = -1.0\n","    summaries = []\n","    for _ in range(min(max_summary_sentences, n_sentences)):\n","        for i in range(n_sentences):\n","            if i in oracle_summary_sentences:\n","                continue\n","            current_summary_sentences = copy.copy(oracle_summary_sentences)\n","            # Добавляем какое-то предложения к уже существующему summary\n","            current_summary_sentences.add(i)\n","            current_summary = \" \".join([sentences[index] for index in sorted(list(current_summary_sentences))])\n","            # Считаем метрики\n","            current_score = calc_score(current_summary, gold_summary)\n","            summaries.append((current_score, current_summary_sentences))\n","        # Если получилось улучшить метрики с добавлением какого-либо предложения, то пробуем добавить ещё\n","        # Иначе на этом заканчиваем\n","        best_summary_score, best_summary_sentences = max(summaries)\n","        if best_summary_score <= score:\n","            break\n","        oracle_summary_sentences = best_summary_sentences\n","        score = best_summary_score\n","    oracle_summary = \" \".join([sentences[index] for index in sorted(list(oracle_summary_sentences))])\n","    return oracle_summary, oracle_summary_sentences\n","\n","def calc_single_score(pred_summary, gold_summary, rouge):\n","    return rouge.get_scores([pred_summary], [gold_summary], avg=True)['rouge-2']['f']"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20784,"status":"ok","timestamp":1681138228095,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"7T_ak-KDB8rp","outputId":"780c8da8-fb1e-44b1-970f-b00e017a6c48"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [00:20<00:00,  4.88it/s]"]},{"output_type":"stream","name":"stdout","text":["Tar: хорею гентингтона, тяжелое наследственное заболевание нервной системы, можно вылечить, считает международная группа исследователей. им удалось снизить число тринуклеотидных повторов, которое приводит к появлению симптомов. также новый способ лечения будет эффективен и против других заболеваний похожей природы.\n","Pred: хорея гентингтона — генетическое заболевание нервной системы, которое возникает из-за мутации гена htt. чем больше количество тринуклеотидных повторов, тем раньше проявляются симптомы. выраженность данных симптомов носит прогрессирующий характер и со временем приводит к инвалидности.\n","BLEU:  0.14839518337610041\n","ROUGE:  {'rouge-1': {'f': 0.37838584385776053, 'p': 0.40855677080118313, 'r': 0.3826106742462572}, 'rouge-2': {'f': 0.21369184587032666, 'p': 0.24043335812746858, 'r': 0.21216642563063615}, 'rouge-l': {'f': 0.3337345310991497, 'p': 0.3835169293425399, 'r': 0.35807248520225543}}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["def calc_oracle_score(records, nrows=100, lower=True):\n","    references = []\n","    predictions = []\n","    rouge = Rouge()\n","  \n","    for record in tqdm(records[:nrows]):\n","        summary = record[\"summary\"]\n","        summary = summary if not lower else summary.lower()\n","        references.append(summary)\n","\n","        text = record[\"text\"]\n","        predicted_summary, _ = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge))\n","        predictions.append(predicted_summary)\n","\n","    calc_scores(references, predictions)\n","\n","\n","calc_oracle_score(test_records)"]},{"cell_type":"markdown","metadata":{"id":"foLYftYTCAkS"},"source":["## Extractive RNN"]},{"cell_type":"markdown","metadata":{"id":"PYrjp9FtGdST"},"source":["Теперь пробуем предсказать oracle summary"]},{"cell_type":"markdown","metadata":{"id":"7Sfauc4VGgyw"},"source":["### BPE\n","Для начала сделаем BPE токенизацию"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":36684,"status":"ok","timestamp":1681138264761,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"AwimS4UeZCtR"},"outputs":[],"source":["from tokenizers import ByteLevelBPETokenizer\n","\n","tokenizer = ByteLevelBPETokenizer(lowercase=True)\n","\n","tokenizer.train_from_iterator([record['text'] for record in train_records[:1000]], vocab_size=8192, show_progress=True)"]},{"cell_type":"markdown","metadata":{"id":"seH13yXuGt03"},"source":["### Кэш oracle summary\n","Закэшируем oracle summary, чтобы не пересчитывать их каждый раз"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jdb-39jO-72q","outputId":"19f45391-d5ed-4d5e-a65c-b3192471bc2b","executionInfo":{"status":"ok","timestamp":1680864801898,"user_tz":-180,"elapsed":1711150,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 16384/16384 [40:12<00:00,  6.79it/s]\n","100%|██████████| 1024/1024 [03:05<00:00,  5.52it/s]\n","100%|██████████| 1024/1024 [02:55<00:00,  5.84it/s]\n"]}],"source":["from rouge import Rouge\n","import razdel\n","\n","from tqdm import tqdm\n","\n","def add_oracle_summary_to_records(records, max_sentences=30, lower=True, nrows=1000):\n","    rouge = Rouge()\n","    for record in tqdm(records[:nrows]):\n","        text = record[\"text\"]\n","        summary = record[\"summary\"]\n","        summary = summary.lower() if lower else summary\n","        sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n","        oracle_summary, sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge),\n","                                                                         lower=lower)\n","        record[\"sentences\"] = sentences\n","        record[\"oracle_sentences\"] = list(sentences_indicies)\n","        record[\"oracle_summary\"] = oracle_summary\n","    return records[:nrows]\n","\n","ext_train_records = add_oracle_summary_to_records(train_records, nrows=16384)\n","ext_val_records = add_oracle_summary_to_records(val_records, nrows=1024)\n","ext_test_records = add_oracle_summary_to_records(test_records, nrows=1024)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"30tUpRQtq1fb"},"outputs":[],"source":["import json\n","\n","def write_gazeta_records(records, file_name):\n","    with open(file_name, \"w\") as w:\n","        for record in records:\n","            record[\"oracle_sentences\"] = list(record[\"oracle_sentences\"])\n","            w.write(json.dumps(record, ensure_ascii=False).strip() + \"\\n\")\n","\n","write_gazeta_records(ext_train_records, \"gazeta_train_with_oracle.txt\")\n","write_gazeta_records(ext_val_records, \"gazeta_val_with_oracle.txt\")\n","write_gazeta_records(ext_test_records, \"gazeta_test_with_oracle.txt\")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"CzyD29AQJHHm","executionInfo":{"status":"ok","timestamp":1681138266926,"user_tz":-180,"elapsed":2170,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"}}},"outputs":[],"source":["ext_train_records = read_gazeta_records(\"gazeta_train_with_oracle.txt\")\n","ext_val_records = read_gazeta_records(\"gazeta_val_with_oracle.txt\")\n","ext_test_records = read_gazeta_records(\"gazeta_test_with_oracle.txt\")"]},{"cell_type":"markdown","metadata":{"id":"UlXXc8qUHC5m"},"source":["### Составление батчей"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MNyxstTChK3C"},"outputs":[],"source":["import random\n","import math\n","import razdel\n","import torch\n","import numpy as np\n","from rouge import Rouge\n","\n","\n","class BatchIterator():\n","    def __init__(self, records, batch_size, tokenizer, max_sentences=30, max_sentence_length=50, device=torch.device('cuda')):\n","        self.records = records\n","        self.num_samples = len(records)\n","        self.batch_size = batch_size\n","        self.tokenizer = tokenizer\n","        self.batches_count = int(math.ceil(self.num_samples / batch_size))\n","        self.rouge = Rouge()\n","        self.max_sentences = max_sentences\n","        self.max_sentence_length = max_sentence_length\n","        self.device = device #torch.device('cuda')\n","        \n","    def __len__(self):\n","        return self.batches_count\n","    \n","    def __iter__(self):\n","        indices = np.arange(self.num_samples)\n","        np.random.shuffle(indices)\n","\n","        for start in range(0, self.num_samples, self.batch_size):\n","            end = min(start + self.batch_size, self.num_samples)\n","            batch_indices = indices[start:end]\n","            batch_inputs = []\n","            batch_outputs = []\n","            max_sentence_length = 0\n","            max_sentences = 0\n","            batch_records = []\n","            for data_ind in batch_indices:\n","                record = self.records[data_ind]\n","                batch_records.append(record)\n","                text = record[\"text\"]\n","                summary = record[\"summary\"]\n","                summary = summary.lower()\n","\n","                if \"sentences\" not in record:\n","                    sentences = [sentence.text.lower() for sentence in razdel.sentenize(text)][:self.max_sentences]\n","                else:\n","                    sentences = record[\"sentences\"]\n","                max_sentences = max(len(sentences), max_sentences)\n","\n","                if \"oracle_sentences\" not in record:\n","                    calc_score = lambda x, y: calc_single_score(x, y, self.rouge)\n","                    sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=calc_score, max_sentences=self.max_sentences)[1]\n","                else:\n","                    sentences_indicies = record[\"oracle_sentences\"]\n","\n","                inputs = [tokenizer.encode(sentence).ids[:self.max_sentence_length] for sentence in sentences]\n","                max_sentence_length = max(max_sentence_length, max([len(tokens) for tokens in inputs]))\n","                outputs = [int(i in sentences_indicies) for i in range(len(sentences))]\n","                batch_inputs.append(inputs)\n","                batch_outputs.append(outputs)\n","            tensor_inputs = torch.zeros((self.batch_size, max_sentences, max_sentence_length), dtype=torch.long, device=self.device)\n","            tensor_outputs = torch.zeros((self.batch_size, max_sentences), dtype=torch.float32, device=self.device)\n","            for i, inputs in enumerate(batch_inputs):\n","                for j, sentence_tokens in enumerate(inputs):\n","                    tensor_inputs[i][j][:len(sentence_tokens)] = torch.LongTensor(sentence_tokens)\n","            for i, outputs in enumerate(batch_outputs):\n","                tensor_outputs[i][:len(outputs)] = torch.LongTensor(outputs)\n","\n","            yield {\n","                'inputs': tensor_inputs,\n","                'outputs': tensor_outputs,\n","                'records': batch_records\n","            }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JegA9fOMsZN5"},"outputs":[],"source":["train_iterator = BatchIterator(ext_train_records, 32, tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"4q2Gb6ODHHB_"},"source":["### Обучение"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5ZApHkw2Jq-"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import time\n","\n","def train_model(model, train_records, val_records, tokenizer, batch_size=32,\n","                epochs_count=10, loss_every_nsteps=16, lr=0.001, device_name=\"cuda\"):\n","    params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print(\"Trainable params: {}\".format(params_count))\n","    device = torch.device(device_name)\n","    model = model.to(device)\n","    total_loss = 0\n","    start_time = time.time()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    loss_function = nn.BCEWithLogitsLoss().to(device)\n","    for epoch in range(epochs_count):\n","        for step, batch in enumerate(BatchIterator(train_records, batch_size, tokenizer, device=device)):\n","            model.train()\n","            logits = model(batch[\"inputs\"])\n","            loss = loss_function(logits, batch[\"outputs\"])\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            total_loss += loss.item()\n","            if step % loss_every_nsteps == 0 and step != 0:\n","                val_total_loss = 0\n","                val_batch_count = 0\n","                model.eval()\n","                for _, val_batch in enumerate(BatchIterator(val_records, batch_size, tokenizer, device=device)):\n","                    logits = model(val_batch[\"inputs\"])\n","                    val_total_loss += loss_function(logits, batch[\"outputs\"])\n","                    val_batch_count += 1\n","                avg_val_loss = val_total_loss/val_batch_count\n","                print(f\"Epoch = {epoch}, Avg Train Loss = {total_loss / loss_every_nsteps:.4f}, Avg val loss = {avg_val_loss:.4f}, Time = {time.time() - start_time:.2f}s\")\n","                total_loss = 0\n","                start_time = time.time()\n","        total_loss = 0\n","        start_time = time.time()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":712307,"status":"error","timestamp":1680796806476,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"PYmCkxqbxoW1","outputId":"4bb2b66c-6ace-423f-a97f-336eb627d862"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"name":"stdout","output_type":"stream","text":["Trainable params: 4466177\n","Epoch = 0, Avg Train Loss = 0.3345, Avg val loss = 0.2425, Time = 13.44s\n","Epoch = 0, Avg Train Loss = 0.2461, Avg val loss = 0.2337, Time = 8.15s\n","Epoch = 0, Avg Train Loss = 0.2366, Avg val loss = 0.2534, Time = 8.86s\n","Epoch = 0, Avg Train Loss = 0.2388, Avg val loss = 0.2448, Time = 9.49s\n","Epoch = 0, Avg Train Loss = 0.2341, Avg val loss = 0.2348, Time = 7.90s\n","Epoch = 0, Avg Train Loss = 0.2356, Avg val loss = 0.2531, Time = 9.03s\n","Epoch = 0, Avg Train Loss = 0.2299, Avg val loss = 0.2389, Time = 9.07s\n","Epoch = 0, Avg Train Loss = 0.2350, Avg val loss = 0.2393, Time = 8.38s\n","Epoch = 0, Avg Train Loss = 0.2281, Avg val loss = 0.2239, Time = 9.48s\n","Epoch = 0, Avg Train Loss = 0.2281, Avg val loss = 0.2471, Time = 7.85s\n","Epoch = 0, Avg Train Loss = 0.2269, Avg val loss = 0.2541, Time = 9.13s\n","Epoch = 0, Avg Train Loss = 0.2361, Avg val loss = 0.2834, Time = 10.73s\n","Epoch = 0, Avg Train Loss = 0.2368, Avg val loss = 0.2764, Time = 7.97s\n","Epoch = 0, Avg Train Loss = 0.2243, Avg val loss = 0.2362, Time = 9.02s\n","Epoch = 0, Avg Train Loss = 0.2275, Avg val loss = 0.2342, Time = 9.98s\n","Epoch = 0, Avg Train Loss = 0.2241, Avg val loss = 0.2418, Time = 8.11s\n","Epoch = 0, Avg Train Loss = 0.2251, Avg val loss = 0.2372, Time = 9.50s\n","Epoch = 0, Avg Train Loss = 0.2283, Avg val loss = 0.2223, Time = 9.02s\n","Epoch = 0, Avg Train Loss = 0.2210, Avg val loss = 0.2296, Time = 8.80s\n","Epoch = 0, Avg Train Loss = 0.2281, Avg val loss = 0.2376, Time = 11.61s\n","Epoch = 0, Avg Train Loss = 0.2316, Avg val loss = 0.2299, Time = 11.42s\n","Epoch = 0, Avg Train Loss = 0.2265, Avg val loss = 0.2659, Time = 7.99s\n","Epoch = 0, Avg Train Loss = 0.2263, Avg val loss = 0.2319, Time = 9.85s\n","Epoch = 0, Avg Train Loss = 0.2231, Avg val loss = 0.2442, Time = 10.13s\n","Epoch = 0, Avg Train Loss = 0.2230, Avg val loss = 0.2146, Time = 8.06s\n","Epoch = 0, Avg Train Loss = 0.2158, Avg val loss = 0.2236, Time = 9.12s\n","Epoch = 0, Avg Train Loss = 0.2176, Avg val loss = 0.2453, Time = 10.23s\n","Epoch = 0, Avg Train Loss = 0.2288, Avg val loss = 0.2297, Time = 11.95s\n","Epoch = 0, Avg Train Loss = 0.2271, Avg val loss = 0.2538, Time = 8.65s\n","Epoch = 0, Avg Train Loss = 0.2257, Avg val loss = 0.2420, Time = 9.37s\n","Epoch = 0, Avg Train Loss = 0.2270, Avg val loss = 0.2260, Time = 8.17s\n","Epoch = 1, Avg Train Loss = 0.2295, Avg val loss = 0.2466, Time = 8.19s\n","Epoch = 1, Avg Train Loss = 0.2130, Avg val loss = 0.2760, Time = 9.10s\n","Epoch = 1, Avg Train Loss = 0.2168, Avg val loss = 0.2888, Time = 9.61s\n","Epoch = 1, Avg Train Loss = 0.2253, Avg val loss = 0.2438, Time = 9.43s\n","Epoch = 1, Avg Train Loss = 0.2141, Avg val loss = 0.2711, Time = 9.43s\n","Epoch = 1, Avg Train Loss = 0.2184, Avg val loss = 0.2333, Time = 9.53s\n","Epoch = 1, Avg Train Loss = 0.2246, Avg val loss = 0.2270, Time = 8.26s\n","Epoch = 1, Avg Train Loss = 0.2198, Avg val loss = 0.2171, Time = 9.35s\n","Epoch = 1, Avg Train Loss = 0.2259, Avg val loss = 0.2417, Time = 8.83s\n","Epoch = 1, Avg Train Loss = 0.2205, Avg val loss = 0.2449, Time = 8.65s\n","Epoch = 1, Avg Train Loss = 0.2166, Avg val loss = 0.2359, Time = 9.57s\n","Epoch = 1, Avg Train Loss = 0.2155, Avg val loss = 0.2586, Time = 9.43s\n","Epoch = 1, Avg Train Loss = 0.2121, Avg val loss = 0.2082, Time = 8.80s\n","Epoch = 1, Avg Train Loss = 0.2178, Avg val loss = 0.2088, Time = 9.64s\n","Epoch = 1, Avg Train Loss = 0.2117, Avg val loss = 0.2483, Time = 8.05s\n","Epoch = 1, Avg Train Loss = 0.2239, Avg val loss = 0.2100, Time = 9.06s\n","Epoch = 1, Avg Train Loss = 0.2191, Avg val loss = 0.2586, Time = 9.83s\n","Epoch = 1, Avg Train Loss = 0.2201, Avg val loss = 0.2563, Time = 8.52s\n","Epoch = 1, Avg Train Loss = 0.2135, Avg val loss = 0.2553, Time = 9.20s\n","Epoch = 1, Avg Train Loss = 0.2215, Avg val loss = 0.2836, Time = 9.80s\n","Epoch = 1, Avg Train Loss = 0.2207, Avg val loss = 0.2359, Time = 8.17s\n","Epoch = 1, Avg Train Loss = 0.2140, Avg val loss = 0.2746, Time = 9.26s\n","Epoch = 1, Avg Train Loss = 0.2185, Avg val loss = 0.2369, Time = 9.23s\n","Epoch = 1, Avg Train Loss = 0.2239, Avg val loss = 0.2751, Time = 8.52s\n","Epoch = 1, Avg Train Loss = 0.2250, Avg val loss = 0.2640, Time = 9.70s\n","Epoch = 1, Avg Train Loss = 0.2139, Avg val loss = 0.2321, Time = 12.52s\n","Epoch = 1, Avg Train Loss = 0.2217, Avg val loss = 0.2647, Time = 8.16s\n","Epoch = 1, Avg Train Loss = 0.2176, Avg val loss = 0.2418, Time = 10.14s\n","Epoch = 1, Avg Train Loss = 0.2149, Avg val loss = 0.2102, Time = 9.75s\n","Epoch = 1, Avg Train Loss = 0.2116, Avg val loss = 0.2323, Time = 8.12s\n","Epoch = 1, Avg Train Loss = 0.2202, Avg val loss = 0.2621, Time = 9.74s\n","Epoch = 2, Avg Train Loss = 0.2158, Avg val loss = 0.2606, Time = 9.36s\n","Epoch = 2, Avg Train Loss = 0.2022, Avg val loss = 0.2555, Time = 9.47s\n","Epoch = 2, Avg Train Loss = 0.2013, Avg val loss = 0.2669, Time = 8.43s\n","Epoch = 2, Avg Train Loss = 0.2033, Avg val loss = 0.2833, Time = 9.46s\n","Epoch = 2, Avg Train Loss = 0.2121, Avg val loss = 0.2591, Time = 8.85s\n","Epoch = 2, Avg Train Loss = 0.2127, Avg val loss = 0.2389, Time = 8.93s\n","Epoch = 2, Avg Train Loss = 0.2020, Avg val loss = 0.2392, Time = 10.52s\n","Epoch = 2, Avg Train Loss = 0.2050, Avg val loss = 0.2782, Time = 11.59s\n","Epoch = 2, Avg Train Loss = 0.2142, Avg val loss = 0.2662, Time = 8.77s\n","Epoch = 2, Avg Train Loss = 0.2040, Avg val loss = 0.2480, Time = 10.19s\n","Epoch = 2, Avg Train Loss = 0.2059, Avg val loss = 0.2529, Time = 10.08s\n","Epoch = 2, Avg Train Loss = 0.2103, Avg val loss = 0.2622, Time = 8.85s\n","Epoch = 2, Avg Train Loss = 0.2118, Avg val loss = 0.2560, Time = 9.28s\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-92-77adb8f81550>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTaggerRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_train_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_val_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-91-fdd3fa5ca8d9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_records, val_records, tokenizer, batch_size, epochs_count, loss_every_nsteps, lr, device_name)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-89-d66058267537>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0msentences_indicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"oracle_sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mmax_sentence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences_indicies\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-89-d66058267537>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0msentences_indicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"oracle_sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mmax_sentence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences_indicies\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tokenizers/implementations/base_tokenizer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sequence, pair, is_pretokenized, add_special_tokens)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encode: `sequence` can't be `None`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_pretokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     def encode_batch(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.nn.utils.rnn import pack_padded_sequence as pack\n","from torch.nn.utils.rnn import pad_packed_sequence as unpack\n","\n","class SentenceEncoderRNN(nn.Module):\n","    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3):\n","        super(SentenceEncoderRNN, self).__init__()\n","\n","        self.embedding_dim = embedding_dim\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n","        self.rnn_layer = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=True, batch_first=True)\n","        self.dropout_layer = nn.Dropout(dropout)\n","\n","    def forward(self, inputs, hidden=None):\n","        embedded = self.embedding_layer(inputs)\n","        outputs, _ = self.rnn_layer(embedded, hidden)\n","        sentences_embeddings = torch.mean(outputs, 1)\n","        return sentences_embeddings\n","\n","class SentenceTaggerRNN(nn.Module):\n","    def __init__(self,\n","                 vocabulary_size,\n","                 token_embedding_dim=256,\n","                 sentence_encoder_hidden_size=256,\n","                 hidden_size=256,\n","                 sentence_encoder_n_layers=2,\n","                 sentence_encoder_dropout=0.3,\n","                 n_layers=1,\n","                 dropout=0.3):\n","        super(SentenceTaggerRNN, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","        \n","        self.sentence_encoder = SentenceEncoderRNN(vocabulary_size, token_embedding_dim,\n","                                                   sentence_encoder_hidden_size // 2, sentence_encoder_n_layers, \n","                                                   sentence_encoder_dropout)\n","        self.rnn_layer = nn.LSTM(sentence_encoder_hidden_size, hidden_size, n_layers, dropout=dropout,\n","                           bidirectional=True, batch_first=True)\n","        self.dropout_layer = nn.Dropout(dropout)\n","        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n","        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n","        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n","        \n","\n","    def forward(self, inputs, hidden=None):\n","        batch_size = inputs.size(0)\n","        sentences_count = inputs.size(1)\n","        tokens_count = inputs.size(2)\n","        inputs = inputs.reshape(-1, tokens_count)\n","        \n","        embedded_sentences = self.sentence_encoder(inputs)\n","        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n","        \n","        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n","        outputs = self.dropout_layer(outputs)\n","        document_embedding = self.document_linear_layer(outputs.mean(dim=1)).tanh()\n","        \n","        content = self.content_linear_layer(outputs).squeeze(2)\n","        salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2)\n","        \n","        return content + salience\n","\n","model = SentenceTaggerRNN(tokenizer.get_vocab_size())\n","train_model(model, ext_train_records, ext_val_records, tokenizer, device_name=\"cuda\", batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9232,"status":"ok","timestamp":1680796822263,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"},"user_tz":-180},"id":"EwqhK2dyKuGL","outputId":"76f03b29-953b-4e1b-df2e-751ac362d0f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tar: наличие оргазма — не признак хорошего секса, сообщают американские исследователи. он может наступить и при нежеланном контакте, неся лишь болезненность и смятение.\n","Pred: наличие оргазма — не признак хорошего секса, заявляют ученые из мичиганского университета на основании результатов своего исследования.\n","BLEU:  0.04461730041418153\n","ROUGE:  {'rouge-1': {'f': 0.23533772085273544, 'p': 0.36965082381956776, 'r': 0.1836141877424964}, 'rouge-2': {'f': 0.11232423476358996, 'p': 0.18141057010646255, 'r': 0.08733431960907764}, 'rouge-l': {'f': 0.17614494478587653, 'p': 0.3314016191131096, 'r': 0.16360844212318426}}\n"]}],"source":["device = torch.device(\"cuda\")\n","\n","references = []\n","predictions = []\n","for step, batch in enumerate(BatchIterator(ext_test_records, 32, tokenizer, device=device)):\n","    logits = model(batch[\"inputs\"])\n","    records = batch[\"records\"]\n","    for record, record_logits in zip(records, logits):\n","        sentences = record[\"sentences\"]\n","        predicted_summary = []\n","        for i, logit in enumerate(record_logits):\n","            if logit > 0.0:\n","                predicted_summary.append(sentences[i])\n","        if not predicted_summary:\n","            predicted_summary.append(sentences[torch.max(record_logits, dim=0)[1].item()])\n","        predicted_summary = \" \".join(predicted_summary)\n","        references.append(record[\"summary\"].lower())\n","        predictions.append(predicted_summary)\n","\n","calc_scores(references, predictions)"]},{"cell_type":"markdown","metadata":{"id":"ZbnJMx3yOlAK"},"source":["### **Задание 2**\n","Доделайте модель в соответствии с https://arxiv.org/pdf/1611.04230.pdf"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"mEQCFcaXPv8K","executionInfo":{"status":"ok","timestamp":1681138268774,"user_tz":-180,"elapsed":1867,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"}}},"outputs":[],"source":["import random\n","import math\n","import razdel\n","import torch\n","import numpy as np\n","from rouge import Rouge\n","\n","\n","class BatchIterator():\n","    def __init__(self, records, batch_size, tokenizer, max_sentences=30, max_sentence_length=50, device=torch.device('cuda')):\n","        self.records = records\n","        self.num_samples = len(records)\n","        self.batch_size = batch_size\n","        self.tokenizer = tokenizer\n","        self.batches_count = int(math.ceil(self.num_samples / batch_size))\n","        self.rouge = Rouge()\n","        self.max_sentences = max_sentences\n","        self.max_sentence_length = max_sentence_length\n","        self.device = device #torch.device('cuda')\n","        \n","    def __len__(self):\n","        return self.batches_count\n","    \n","    def __iter__(self):\n","        indices = np.arange(self.num_samples)\n","        np.random.shuffle(indices)\n","\n","        for start in range(0, self.num_samples, self.batch_size):\n","            end = min(start + self.batch_size, self.num_samples)\n","            batch_indices = indices[start:end]\n","            batch_inputs = []\n","            doc_lens = []\n","            batch_outputs = []\n","            max_sentence_length = 0\n","            max_sentences = 0\n","            batch_records = []\n","            for data_ind in batch_indices:\n","                record = self.records[data_ind]\n","                batch_records.append(record)\n","                text = record[\"text\"]\n","                summary = record[\"summary\"]\n","                summary = summary.lower()\n","\n","                if \"sentences\" not in record:\n","                    sentences = [sentence.text.lower() for sentence in razdel.sentenize(text)][:self.max_sentences]\n","                else:\n","                    sentences = record[\"sentences\"]\n","\n","                doc_lens.append(len(sentences))\n","                \n","                max_sentences = max(len(sentences), max_sentences)\n","\n","                if \"oracle_sentences\" not in record:\n","                    calc_score = lambda x, y: calc_single_score(x, y, self.rouge)\n","                    sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=calc_score, max_sentences=self.max_sentences)[1]\n","                else:\n","                    sentences_indicies = record[\"oracle_sentences\"]\n","\n","                inputs = [tokenizer.encode(sentence).ids[:self.max_sentence_length] for sentence in sentences]\n","                max_sentence_length = max(max_sentence_length, max([len(tokens) for tokens in inputs]))\n","                outputs = [int(i in sentences_indicies) for i in range(len(sentences))]\n","                batch_inputs.append(inputs)\n","                batch_outputs.append(outputs)\n","            tensor_inputs = torch.zeros((self.batch_size, max_sentences, max_sentence_length), dtype=torch.long, device=self.device)\n","            tensor_outputs = torch.zeros((self.batch_size, max_sentences), dtype=torch.float32, device=self.device)\n","            for i, inputs in enumerate(batch_inputs):\n","                for j, sentence_tokens in enumerate(inputs):\n","                    tensor_inputs[i][j][:len(sentence_tokens)] = torch.LongTensor(sentence_tokens)\n","            for i, outputs in enumerate(batch_outputs):\n","                tensor_outputs[i][:len(outputs)] = torch.LongTensor(outputs)\n","\n","            yield {\n","                'inputs': tensor_inputs,\n","                'outputs': tensor_outputs,\n","                'records': batch_records,\n","                'doc_lens': doc_lens\n","            }"]},{"cell_type":"code","source":["train_iterator = BatchIterator(ext_train_records, 32, tokenizer)"],"metadata":{"id":"1OWNnLsSK8LE","executionInfo":{"status":"ok","timestamp":1681138268775,"user_tz":-180,"elapsed":14,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"id":"t2kNEsBIRE2S","executionInfo":{"status":"ok","timestamp":1681138268776,"user_tz":-180,"elapsed":12,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import time\n","\n","def train_model(model, train_records, val_records, tokenizer, batch_size=32,\n","                epochs_count=10, loss_every_nsteps=16, lr=0.001, device_name=\"cuda\"):\n","    params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print(\"Trainable params: {}\".format(params_count))\n","    device = torch.device(device_name)\n","    model = model.to(device)\n","    total_loss = 0\n","    start_time = time.time()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    loss_function = nn.BCELoss().to(device)\n","    for epoch in range(epochs_count):\n","        for step, batch in enumerate(BatchIterator(train_records, batch_size, tokenizer, device=device)):\n","            model.train()\n","            logits = model(batch[\"inputs\"], batch[\"doc_lens\"], device)\n","            loss = loss_function(logits, batch[\"outputs\"])\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            total_loss += loss.item()\n","            if step % loss_every_nsteps == 0 and step != 0:\n","                val_total_loss = 0\n","                val_batch_count = 0\n","                model.eval()\n","                for _, val_batch in enumerate(BatchIterator(val_records, batch_size, tokenizer, device=device)):\n","                    logits = model(val_batch[\"inputs\"], batch[\"doc_lens\"], device)\n","                    val_total_loss += loss_function(logits, batch[\"outputs\"])\n","                    val_batch_count += 1\n","                avg_val_loss = val_total_loss/val_batch_count\n","                print(f\"Epoch = {epoch}, Avg Train Loss = {total_loss / loss_every_nsteps:.4f}, Avg val loss = {avg_val_loss:.4f}, Time = {time.time() - start_time:.2f}s\")\n","                total_loss = 0\n","                start_time = time.time()\n","        total_loss = 0\n","        start_time = time.time()"]},{"cell_type":"code","source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.nn.utils.rnn import pack_padded_sequence as pack\n","from torch.nn.utils.rnn import pad_packed_sequence as unpack\n","\n","class SentenceEncoderRNN(nn.Module):\n","    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3):\n","        super(SentenceEncoderRNN, self).__init__()\n","\n","        self.embedding_dim = embedding_dim\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n","        self.rnn_layer = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=True, batch_first=True)\n","        self.dropout_layer = nn.Dropout(dropout)\n","\n","    def forward(self, inputs, hidden=None):\n","        embedded = self.embedding_layer(inputs)\n","        outputs, _ = self.rnn_layer(embedded, hidden)\n","        sentences_embeddings = torch.mean(outputs, 1)\n","        return sentences_embeddings\n","\n","class SentenceTaggerRNN(nn.Module):\n","    def __init__(self,\n","                 vocabulary_size,\n","                 token_embedding_dim=256,\n","                 seg_num=3,\n","                 pos_num=30,\n","                 pos_dim=50,\n","                 sentence_encoder_hidden_size=256,\n","                 hidden_size=256,\n","                 sentence_encoder_n_layers=2,\n","                 sentence_encoder_dropout=0.3,\n","                 n_layers=1,\n","                 dropout=0.3):\n","        super(SentenceTaggerRNN, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        self.abs_pos_embed = nn.Embedding(pos_num, pos_dim)  # absolute postion\n","        self.rel_pos_embed = nn.Embedding(seg_num, pos_dim)  # relative position\n","        \n","        self.sentence_encoder = SentenceEncoderRNN(vocabulary_size, token_embedding_dim,\n","                                                   sentence_encoder_hidden_size // 2, sentence_encoder_n_layers, \n","                                                   sentence_encoder_dropout)\n","        self.rnn_layer = nn.LSTM(sentence_encoder_hidden_size, hidden_size, n_layers, dropout=dropout,\n","                           bidirectional=True, batch_first=True)\n","        self.dropout_layer = nn.Dropout(dropout)\n","        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n","\n","        self.content = nn.Linear(2*hidden_size, 1, bias=False)\n","        self.salience = nn.Bilinear(2*hidden_size, 2*hidden_size, 1, bias=False)\n","        self.novelty = nn.Bilinear(2*hidden_size, 2*hidden_size, 1, bias=False)\n","        self.abs_pos = nn.Linear(pos_dim, 1, bias=False)\n","        self.rel_pos = nn.Linear(pos_dim, 1, bias=False)\n","        self.bias = nn.Parameter(torch.FloatTensor(1).uniform_(-0.1, 0.1))\n","        \n","\n","    def forward(self, inputs, doc_lens, device, hidden=None):\n","        batch_size = inputs.size(0)\n","        sentences_count = inputs.size(1)\n","        tokens_count = inputs.size(2)\n","        inputs = inputs.reshape(-1, tokens_count)\n","        \n","        embedded_sentences = self.sentence_encoder(inputs)\n","        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n","        \n","        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n","        outputs = self.dropout_layer(outputs)\n","        document_embedding = self.document_linear_layer(outputs.mean(dim=1)).tanh()\n","\n","        probs = []\n","\n","        for index in range(batch_size):\n","          valid_hidden = outputs[index, :, :]\n","          doc = document_embedding[index, :].view(1, -1)\n","          s = torch.zeros([1, 2*self.hidden_size], device=device, requires_grad=True)\n","          sent_probs = []\n","\n","          for position, h in enumerate(valid_hidden):\n","              h = h.view(1, -1)\n","\n","              abs_index = torch.tensor([[position]], dtype=torch.long).to(device) \n","              abs_features = self.abs_pos_embed(abs_index).squeeze(0)\n","\n","              rel_index = round((position + 1) * 9.0 / sentences_count)\n","              rel_index = torch.tensor([[rel_index]], dtype=torch.long).to(device)\n","              rel_features = self.rel_pos_embed(rel_index).squeeze(0)\n","\n","              content = self.content(h)\n","              salience = self.salience(h, doc)\n","              novelty = -1 * self.novelty(h, torch.tanh(s))\n","              abs_p = self.abs_pos(abs_features)\n","              rel_p = self.rel_pos(rel_features)\n","\n","              prob = torch.sigmoid(content + salience + novelty + abs_p + rel_p + self.bias)\n","              s = s + torch.mm(prob, h)\n","              sent_probs.append(prob)\n","        \n","          probs.append(torch.cat(sent_probs).squeeze())\n","        \n","        return torch.cat(probs, dim=0).reshape(batch_size, sentences_count)\n","\n","model = SentenceTaggerRNN(tokenizer.get_vocab_size())\n","train_model(model, ext_train_records, ext_val_records, tokenizer, device_name=\"cuda\", batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"id":"z_-lz1_WlI5W","executionInfo":{"status":"error","timestamp":1681138275048,"user_tz":-180,"elapsed":1476,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"}},"outputId":"69f8d9b9-83f0-4d8f-cf3f-e27900d9b777"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 4729559\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-341b238406b0>\u001b[0m in \u001b[0;36m<cell line: 115>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTaggerRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_train_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_val_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-8175e398e7a0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_records, val_records, tokenizer, batch_size, epochs_count, loss_every_nsteps, lr, device_name)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"doc_lens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-341b238406b0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, doc_lens, device, hidden)\u001b[0m\n\u001b[1;32m    104\u001b[0m               \u001b[0mrel_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m               \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msalience\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnovelty\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mabs_p\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrel_p\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m               \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m               \u001b[0msent_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"4Kc0etEGfJ0p","outputId":"369070c3-0335-442f-d96c-d048618e2664","executionInfo":{"status":"error","timestamp":1681135122200,"user_tz":-180,"elapsed":4965852,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 4733409\n","Epoch = 0, Avg Train Loss = 0.2949, Avg val loss = 0.2196, Time = 64.95s\n","Epoch = 0, Avg Train Loss = 0.2438, Avg val loss = 0.2167, Time = 63.10s\n","Epoch = 0, Avg Train Loss = 0.2371, Avg val loss = 0.2008, Time = 62.93s\n","Epoch = 0, Avg Train Loss = 0.2330, Avg val loss = 0.2627, Time = 63.70s\n","Epoch = 0, Avg Train Loss = 0.2274, Avg val loss = 0.2168, Time = 63.66s\n","Epoch = 0, Avg Train Loss = 0.2265, Avg val loss = 0.2063, Time = 62.42s\n","Epoch = 0, Avg Train Loss = 0.2273, Avg val loss = 0.2296, Time = 64.00s\n","Epoch = 0, Avg Train Loss = 0.2218, Avg val loss = 0.2250, Time = 63.86s\n","Epoch = 0, Avg Train Loss = 0.2353, Avg val loss = 0.2559, Time = 62.69s\n","Epoch = 0, Avg Train Loss = 0.2194, Avg val loss = 0.2039, Time = 64.04s\n","Epoch = 0, Avg Train Loss = 0.2304, Avg val loss = 0.2125, Time = 63.29s\n","Epoch = 0, Avg Train Loss = 0.2204, Avg val loss = 0.2686, Time = 64.01s\n","Epoch = 0, Avg Train Loss = 0.2243, Avg val loss = 0.2001, Time = 64.56s\n","Epoch = 0, Avg Train Loss = 0.2325, Avg val loss = 0.2309, Time = 63.30s\n","Epoch = 0, Avg Train Loss = 0.2232, Avg val loss = 0.2386, Time = 64.45s\n","Epoch = 0, Avg Train Loss = 0.2232, Avg val loss = 0.2536, Time = 64.21s\n","Epoch = 0, Avg Train Loss = 0.2262, Avg val loss = 0.2388, Time = 62.87s\n","Epoch = 0, Avg Train Loss = 0.2275, Avg val loss = 0.2379, Time = 64.25s\n","Epoch = 0, Avg Train Loss = 0.2252, Avg val loss = 0.2548, Time = 64.41s\n","Epoch = 0, Avg Train Loss = 0.2254, Avg val loss = 0.2409, Time = 62.70s\n","Epoch = 0, Avg Train Loss = 0.2214, Avg val loss = 0.2449, Time = 64.22s\n","Epoch = 0, Avg Train Loss = 0.2271, Avg val loss = 0.2734, Time = 63.26s\n","Epoch = 0, Avg Train Loss = 0.2183, Avg val loss = 0.2398, Time = 62.98s\n","Epoch = 0, Avg Train Loss = 0.2288, Avg val loss = 0.2398, Time = 63.36s\n","Epoch = 0, Avg Train Loss = 0.2235, Avg val loss = 0.2185, Time = 62.21s\n","Epoch = 0, Avg Train Loss = 0.2245, Avg val loss = 0.2241, Time = 63.51s\n","Epoch = 0, Avg Train Loss = 0.2277, Avg val loss = 0.2791, Time = 63.01s\n","Epoch = 0, Avg Train Loss = 0.2301, Avg val loss = 0.2251, Time = 63.53s\n","Epoch = 0, Avg Train Loss = 0.2214, Avg val loss = 0.2800, Time = 64.12s\n","Epoch = 0, Avg Train Loss = 0.2280, Avg val loss = 0.2276, Time = 63.23s\n","Epoch = 0, Avg Train Loss = 0.2265, Avg val loss = 0.2588, Time = 63.60s\n","Epoch = 1, Avg Train Loss = 0.2338, Avg val loss = 0.2572, Time = 65.72s\n","Epoch = 1, Avg Train Loss = 0.2163, Avg val loss = 0.2290, Time = 64.08s\n","Epoch = 1, Avg Train Loss = 0.2216, Avg val loss = 0.2511, Time = 62.24s\n","Epoch = 1, Avg Train Loss = 0.2173, Avg val loss = 0.2630, Time = 63.36s\n","Epoch = 1, Avg Train Loss = 0.2120, Avg val loss = 0.2678, Time = 63.91s\n","Epoch = 1, Avg Train Loss = 0.2182, Avg val loss = 0.2594, Time = 62.29s\n","Epoch = 1, Avg Train Loss = 0.2119, Avg val loss = 0.2783, Time = 63.98s\n","Epoch = 1, Avg Train Loss = 0.2253, Avg val loss = 0.2285, Time = 62.81s\n","Epoch = 1, Avg Train Loss = 0.2151, Avg val loss = 0.2573, Time = 63.49s\n","Epoch = 1, Avg Train Loss = 0.2199, Avg val loss = 0.2494, Time = 63.09s\n","Epoch = 1, Avg Train Loss = 0.2197, Avg val loss = 0.2540, Time = 63.18s\n","Epoch = 1, Avg Train Loss = 0.2236, Avg val loss = 0.2262, Time = 63.35s\n","Epoch = 1, Avg Train Loss = 0.2197, Avg val loss = 0.2404, Time = 61.54s\n","Epoch = 1, Avg Train Loss = 0.2038, Avg val loss = 0.2423, Time = 63.79s\n","Epoch = 1, Avg Train Loss = 0.2200, Avg val loss = 0.2296, Time = 63.94s\n","Epoch = 1, Avg Train Loss = 0.2214, Avg val loss = 0.2745, Time = 62.83s\n","Epoch = 1, Avg Train Loss = 0.2080, Avg val loss = 0.2022, Time = 63.01s\n","Epoch = 1, Avg Train Loss = 0.2265, Avg val loss = 0.2636, Time = 62.92s\n","Epoch = 1, Avg Train Loss = 0.2147, Avg val loss = 0.2513, Time = 63.37s\n","Epoch = 1, Avg Train Loss = 0.2206, Avg val loss = 0.2816, Time = 63.49s\n","Epoch = 1, Avg Train Loss = 0.2166, Avg val loss = 0.2152, Time = 62.98s\n","Epoch = 1, Avg Train Loss = 0.2216, Avg val loss = 0.2508, Time = 63.66s\n","Epoch = 1, Avg Train Loss = 0.2164, Avg val loss = 0.2426, Time = 62.42s\n","Epoch = 1, Avg Train Loss = 0.2175, Avg val loss = 0.2168, Time = 63.41s\n","Epoch = 1, Avg Train Loss = 0.2215, Avg val loss = 0.2663, Time = 64.29s\n","Epoch = 1, Avg Train Loss = 0.2187, Avg val loss = 0.2389, Time = 62.02s\n","Epoch = 1, Avg Train Loss = 0.2164, Avg val loss = 0.2461, Time = 63.53s\n","Epoch = 1, Avg Train Loss = 0.2115, Avg val loss = 0.2530, Time = 63.33s\n","Epoch = 1, Avg Train Loss = 0.2188, Avg val loss = 0.2734, Time = 63.63s\n","Epoch = 1, Avg Train Loss = 0.2149, Avg val loss = 0.2266, Time = 63.88s\n","Epoch = 1, Avg Train Loss = 0.2108, Avg val loss = 0.2384, Time = 64.13s\n","Epoch = 2, Avg Train Loss = 0.2213, Avg val loss = 0.2740, Time = 64.80s\n","Epoch = 2, Avg Train Loss = 0.2029, Avg val loss = 0.2277, Time = 62.53s\n","Epoch = 2, Avg Train Loss = 0.2108, Avg val loss = 0.2813, Time = 65.31s\n","Epoch = 2, Avg Train Loss = 0.2059, Avg val loss = 0.2310, Time = 62.30s\n","Epoch = 2, Avg Train Loss = 0.2142, Avg val loss = 0.2412, Time = 63.70s\n","Epoch = 2, Avg Train Loss = 0.2077, Avg val loss = 0.2437, Time = 63.38s\n","Epoch = 2, Avg Train Loss = 0.2047, Avg val loss = 0.2737, Time = 63.62s\n","Epoch = 2, Avg Train Loss = 0.2090, Avg val loss = 0.2868, Time = 63.85s\n","Epoch = 2, Avg Train Loss = 0.2055, Avg val loss = 0.2186, Time = 63.47s\n","Epoch = 2, Avg Train Loss = 0.2096, Avg val loss = 0.2525, Time = 62.34s\n","Epoch = 2, Avg Train Loss = 0.2031, Avg val loss = 0.2666, Time = 63.90s\n","Epoch = 2, Avg Train Loss = 0.2179, Avg val loss = 0.2899, Time = 62.47s\n","Epoch = 2, Avg Train Loss = 0.2003, Avg val loss = 0.2465, Time = 63.59s\n","Epoch = 2, Avg Train Loss = 0.2099, Avg val loss = 0.2605, Time = 63.58s\n","Epoch = 2, Avg Train Loss = 0.1998, Avg val loss = 0.2649, Time = 62.38s\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-0cecc7fa5c3f>\u001b[0m in \u001b[0;36m<cell line: 118>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTaggerRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_train_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_val_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-8175e398e7a0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_records, val_records, tokenizer, batch_size, epochs_count, loss_every_nsteps, lr, device_name)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"doc_lens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","\n","from torch.nn.utils.rnn import pack_padded_sequence as pack\n","from torch.nn.utils.rnn import pad_packed_sequence as unpack\n","\n","class SentenceEncoderRNN(nn.Module):\n","    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3):\n","        super(SentenceEncoderRNN, self).__init__()\n","\n","        self.embedding_dim = embedding_dim\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n","        self.rnn_layer = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=True, batch_first=True)\n","        self.dropout_layer = nn.Dropout(dropout)\n","\n","    def forward(self, inputs, hidden=None):\n","        embedded = self.embedding_layer(inputs)\n","        outputs, _ = self.rnn_layer(embedded, hidden)\n","        sentences_embeddings = torch.mean(outputs, 1)\n","        return sentences_embeddings\n","\n","class SentenceTaggerRNN(nn.Module):\n","    def __init__(self,\n","                 vocabulary_size,\n","                 token_embedding_dim=256,\n","                 seg_num=10,\n","                 pos_num=100,\n","                 pos_dim=50,\n","                 sentence_encoder_hidden_size=256,\n","                 hidden_size=256,\n","                 sentence_encoder_n_layers=2,\n","                 sentence_encoder_dropout=0.3,\n","                 n_layers=1,\n","                 dropout=0.3):\n","        super(SentenceTaggerRNN, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        self.abs_pos_embed = nn.Embedding(pos_num, pos_dim)  # absolute postion\n","        self.rel_pos_embed = nn.Embedding(seg_num, pos_dim)  # relative position\n","        \n","        self.sentence_encoder = SentenceEncoderRNN(vocabulary_size, token_embedding_dim,\n","                                                   sentence_encoder_hidden_size // 2, sentence_encoder_n_layers, \n","                                                   sentence_encoder_dropout)\n","        self.rnn_layer = nn.LSTM(sentence_encoder_hidden_size, hidden_size, n_layers, dropout=dropout,\n","                           bidirectional=True, batch_first=True)\n","        self.dropout_layer = nn.Dropout(dropout)\n","        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n","\n","        self.content = nn.Linear(2*hidden_size, 1, bias=False)\n","        self.salience = nn.Bilinear(2*hidden_size, 2*hidden_size, 1, bias=False)\n","        self.novelty = nn.Bilinear(2*hidden_size, 2*hidden_size, 1, bias=False)\n","        self.abs_pos = nn.Linear(pos_dim, 1, bias=False)\n","        self.rel_pos = nn.Linear(pos_dim, 1, bias=False)\n","        self.bias = nn.Parameter(torch.FloatTensor(1).uniform_(-0.1, 0.1))\n","        \n","\n","    def forward(self, inputs, doc_lens, device, hidden=None):\n","        batch_size = inputs.size(0)\n","        sentences_count = inputs.size(1)\n","        tokens_count = inputs.size(2)\n","        inputs = inputs.reshape(-1, tokens_count)\n","        \n","        embedded_sentences = self.sentence_encoder(inputs)\n","        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n","        \n","        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n","        outputs = self.dropout_layer(outputs)\n","        document_embedding = self.document_linear_layer(outputs.mean(dim=1)).tanh()\n","\n","        probs = []\n","\n","        for index in range(batch_size):\n","          valid_hidden = outputs[index, :, :]\n","          doc = document_embedding[index, :].view(1, -1)\n","          s = Variable(torch.zeros(1, 2*self.hidden_size)).to(device)\n","          sent_probs = []\n","\n","          for position, h in enumerate(valid_hidden):\n","              h = h.view(1, -1)\n","\n","              abs_index = Variable(torch.LongTensor([[position]])).to(device)\n","              abs_features = self.abs_pos_embed(abs_index).squeeze(0)\n","\n","              rel_index =int(round((position + 1) * 9.0 / sentences_count))\n","              rel_index = Variable(torch.LongTensor([[rel_index]])).to(device)\n","\n","              rel_features = self.rel_pos_embed(rel_index).squeeze(0)\n","\n","              content = self.content(h)\n","              salience = self.salience(h, doc)\n","              novelty = -1 * self.novelty(h, torch.tanh(s))\n","              abs_p = self.abs_pos(abs_features)\n","              rel_p = self.rel_pos(rel_features)\n","\n","              prob = torch.sigmoid(content + salience + novelty + abs_p + rel_p + self.bias)\n","              s = s + torch.mm(prob, h)\n","              sent_probs.append(prob)\n","        \n","          probs.append(torch.cat(sent_probs).squeeze())\n","        \n","        return torch.cat(probs, dim=0).reshape(batch_size, sentences_count)\n","\n","model = SentenceTaggerRNN(tokenizer.get_vocab_size())\n","train_model(model, ext_train_records, ext_val_records, tokenizer, device_name=\"cuda\", batch_size=32)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"GLBRhl6Fbf-d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681135389227,"user_tz":-180,"elapsed":55021,"user":{"displayName":"Степан Сыроваткин","userId":"16512457522786100668"}},"outputId":"5d146e4c-6f09-4140-930b-7834cc93a904"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tar: по указу президента россии владимира путина, в ск, мвд, мчс и фсин был произведен ряд кадровых перестановок. ряд сотрудников этих силовых структур покинули свои должности, а некоторые заняли новые посты. незадолго до этого стало известно, что глава государства отправил в отставку директора фсин геннадия корниенко.\n","Pred: президент россии владимир путин произвел ряд перестановок в следственном комитете (ск), мвд , мчс и федеральной службе исполнения наказаний ( фсин ) россии. соответствующий указ был опубликован 3 октября на официальном интернет-портале правовой информации. глава государства освободил от своих должностей начальника управления фсин по владимирской области андрея винограда, начальника гу мчс по республике коми александра князева , руководителя су ск рф по калининградской области виктора леденева, заместителя начальника гу мвд по новосибирской области, начальника главного следственного управления андрея неупокоева и главного инспектора мвд рф эдуарда соболя. также в отставку были отправлены прокуроры воронежской и томской областей николай шишкин и виктор романенко. тем же указом российский лидер назначил николая басова начальником гу мчс по забайкальскому краю, юрия бобкина — начальником управления планирования и организационно-аналитического обеспечения фсин, а олега кадочникова — замначальника главного управления по вопросам миграции мвд рф. помимо этого, дмитрий ким стал начальником сибирского юридического института мвд рф, дмитрий козлов — начальником гу мчс по севастополю, юрий лымарь — начальником главного управления фсин по пермскому краю, а игорь ромашкин — начальником управления мвд по астраханской области. кроме того, на пятилетний срок на должности руководителей су ск по тверской области и су ск по хмао-югре назначены альберт кизимов и михаил мокшин соответственно. также на пять лет руководителем су ск по смоленской области становится анатолий уханов, а по курганской области — богдан францишко. один из отправленных в отставку сотрудников силовых ведомств — виктор леденев — получил федеральную известность после конфликта с главредом регионального издания «новые колеса» игорем рудниковым. журналист более полутора лет провел в сизо по обвинению в вымогательстве $50 тыс. у генерала леденева. суд не счел действия журналиста вымогательством. по статье о самоуправстве его приговорили к 550 часам обязательных работ. андрей неупокоев отправился в отставку после того, как ск обнаружил в отделе полиции «дзержинский» 82 дела, по которым затягивали сроки следствия. таким образом сотрудники улучшали показатели раскрываемости, потому что пока дело находится в производстве, оно не считается нераскрытым. в связи с этим фактом было возбуждено уголовное дело по признакам превышения служебных полномочий. по завершении служебной проверки глава мвд владимир колокольцев получил ходатайство об освобождении неупокоева от занимаемой должности в связи с неполным служебным соответствием. такие сведения появились в публичном пространстве еще в августе. андрей неупокоев был главным следователем области с марта 2017 года. помимо перечисленных лиц президент также освободил от должности директора фсин генерал-полковника геннадия корниенко. этот указ опубликовали на официальном интернет-портале правовой информации. информацию об этой отставке ранее распространили некоторые сми. журналисты уточняли, что корниенко покидает свой пост из-за предельного возраста пребывания на службе. по информации тасс, это решение было принято еще в конце сентября, когда корниенко исполнилось 65 лет, — это предельный возраст работы в уголовно-исполнительной системе для сотрудника в звании генерал-полковника внутренней службы. сведения об отставке корниенко подтвердили в общественной наблюдательной комиссии (онк) москвы. зампредседателя онк москвы ева меркачева также пояснила «интерфаксу», что отставка связана с возрастом теперь уже бывшего директора фсин. при этом еще 2 октября пресс-секретарь российского президента дмитрий песков отмечал, что указа об увольнении геннадия корниенко с поста главы фсин еще не было. по данным сайта федеральной службы, корниенко получил высшее техническое и высшее специальное образование. у него есть ученая степень кандидата юридических наук, государственные награды и звание генерал-полковника. в 2012 году президент россии назначил его на должность директора фсин. до этого он служил в органах государственной безопасности, работал замдиректора федеральной службы охраны (фсо) рф и занимал пост директора государственной фельдъегерской службы.\n","BLEU:  0.016565257517521033\n","ROUGE:  {'rouge-1': {'f': 0.12819342484571308, 'p': 0.0722033428654248, 'r': 0.6046824348177015}, 'rouge-2': {'f': 0.042832492252103144, 'p': 0.02351190991228701, 'r': 0.256823780554378}, 'rouge-l': {'f': 0.06931714517045258, 'p': 0.06831365970083926, 'r': 0.5726300967848955}}\n"]}],"source":["device = torch.device(\"cuda\")\n","\n","references = []\n","predictions = []\n","for step, batch in enumerate(BatchIterator(ext_test_records, 32, tokenizer, device=device)):\n","    logits = model(batch[\"inputs\"], batch[\"doc_lens\"], device)\n","    records = batch[\"records\"]\n","    for record, record_logits in zip(records, logits):\n","        sentences = record[\"sentences\"]\n","        predicted_summary = []\n","        for i, logit in enumerate(record_logits):\n","            if (logit > 0.0 and i < len(sentences)):\n","                predicted_summary.append(sentences[i])\n","        if not predicted_summary:\n","            predicted_summary.append(sentences[torch.max(record_logits, dim=0)[1].item()])\n","        predicted_summary = \" \".join(predicted_summary)\n","        references.append(record[\"summary\"].lower())\n","        predictions.append(predicted_summary)\n","\n","calc_scores(references, predictions)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1zEPJjCylrdCqlSLDCiKvusxsBiPMt1MU","timestamp":1680789029440},{"file_id":"1x6HGG9dsuOQ7Yro64fmSKJv_YMjeYQaN","timestamp":1650266614824}],"collapsed_sections":["UlXXc8qUHC5m","4q2Gb6ODHHB_"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}